{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc85972",
   "metadata": {},
   "source": [
    "# Dynamic Attention Model (AM-D) Custom Execution\n",
    "\n",
    "This notebook contains code as I explore and test the implementation created by Eremeev and Pustynnikov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bca4a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 10:37:10.555939: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from attention_dynamic_model import AttentionDynamicModel\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77696c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 10:37:40.505385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 10:37:41.858511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 10:37:41.859353: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a2f6aa",
   "metadata": {},
   "source": [
    "## Documentation on the AttentionDynamicModel class\n",
    "\n",
    "The AttentionDynamicModel class is the main model class that implements the AM-D model.\n",
    "\n",
    "### The constructor\n",
    "\n",
    "The constructor of the class will set up the basic attributes of the model as well as all the layers. For the encoder and decoder module, a separate class exists for the encoder, but the decoder is implemented inside this model.\n",
    "```python\n",
    "def __init__(self,\n",
    "             embedding_dim, \n",
    "             n_encode_layers=2, \n",
    "             n_heads=8, \n",
    "             tanh_clipping=10): ...\n",
    "```\n",
    "| Parameter | Description |\n",
    "|:---:|:---|\n",
    "| embedding_dim | The cardinality of the output produced by the embedding projection. This is used to set define the input to the encoder module as well as for the input of the decoder module. |\n",
    "| n_encode_layers | Number of encoder modules stacked |\n",
    "| n_heads | Number of heads used by both encoder and decoder attention modules.|\n",
    "| tanh_clipping | Value used for clipping the attention. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "257c6095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AM-D Model Parameters\n",
    "embedding_dim   = 128\n",
    "n_encode_layers = 2\n",
    "n_heads         = 8\n",
    "tanh_clipping   = 10\n",
    "\n",
    "model_amd = AttentionDynamicModel(\n",
    "    embedding_dim  =embedding_dim,\n",
    "    n_encode_layers=n_encode_layers,\n",
    "    n_heads        =n_heads,\n",
    "    tanh_clipping  =tanh_clipping\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55756fc",
   "metadata": {},
   "source": [
    "#### Setting the Decode Style\n",
    "\n",
    "There are two types of decoding for AM-D:\n",
    "\n",
    "1. Greedy\n",
    "  - Greedy decoding will return the node with the highest probability from the decoder output.\n",
    "2. Sampling\n",
    "  - Sampling decoding will return a random node following the random distribution generated by the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e26c2971",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_amd.set_decode_type('sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7ad2fa",
   "metadata": {},
   "source": [
    "## Selecting Optimizer\n",
    "\n",
    "We have to define an optimizer for the model. See keras' options for this. There are many types to choose from.\n",
    "\n",
    "### Adam\n",
    "```python\n",
    "tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name=\"Adam\",\n",
    "    **kwargs\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e107955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Optimizer Parameters\n",
    "learning_rate = 0.0001\n",
    "beta_1        = 0.9\n",
    "beta_2        = 0.999\n",
    "epsilon       = 1e-07\n",
    "amsgrad       = False\n",
    "name          = \"Adam\"\n",
    "\n",
    "\n",
    "optimizer = Adam(\n",
    "    learning_rate=learning_rate,\n",
    "    beta_1=beta_1,\n",
    "    beta_2=beta_2,\n",
    "    epsilon=epsilon,\n",
    "    amsgrad=amsgrad,\n",
    "    name=name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f48d98e",
   "metadata": {},
   "source": [
    "## Creating a Baseline for More Efficient Reinforcement Learning\n",
    "\n",
    "The AM-D model uses a baseline to help improve the stability of learning. During regular reinforcement learning, it can be challenging to distinguish between actions when the reward obtained may vary based on the state the agent was found on. For example, a set of actions may produce a reward that could be different that the reward obtained starting in a different state that leads to the same end state. This means that the reward variance is high, and it can be hard to compare high reward actions when the initial state is variant. \n",
    "\n",
    "To solve this problem, a baseline can be used. In the past, baselines in RL would be a constant value that helps distinguish states based on a \"neutral\" state that provides information on whether an action is \"better or worse.\" Variance in RL tends to be dependent on the state an agent is found, so we require a dynamic baseline that provides a \"neutral\" baseline to use for comparing the rewards and reach a referendum easier on what actions are better or worse. There are many different baselines, but for AM-D the best traines AM-D policy is used. If better actions are found that produce better reward, then, the baseline can help see these better actions, based on the best actions learned so far.\n",
    "\n",
    "### Rollout Baseline\n",
    "\n",
    "The Rollout baseline is a type of baseline that uses a ML model that produces the best learned actions so far. Whenever the learned model outperforms the baseline (statistically speaking with T-test) then, the baseline is replaced with the learned model.\n",
    "\n",
    "__For the AM-D model, a warm up stage can be used for more stable convergance.__ The way this works is that a combination of exponential moving average baseline is used together with the rolling baseline. At the very begining of learning, the policy for the rollout baseline may be too bad to give meaningful baseline costs. To solve this, we can first rely on exponential moving average that utilizes the mean cost obtained by the training model and the average cost is over time is updated by weighting recently-obtained costs higher than previous ones. This also helps in getting through the initial \"row\" of bad costs obtained by exploration. The Exponential Moving Average (EMA) equation is the following:\n",
    "\n",
    "$M \\leftarrow \\beta M + (1-\\beta) L(\\pi)$\n",
    "\n",
    "Where $M$ is the moving average and $\\beta$ is the weight factor on the importance of previous obtained costs with respect to recent ones. As $\\beta$ approaches 0, recent costs are more important and previous costs are forgoten faster. as $\\beta$ apptoaches 1.0, previous costs are not as forgoten and remain important to recent average cost. Finding a good balance is important because low $\\beta$ will make the average cost be too unstable but high $\\beta$ will make the cost depend too much on early outlier costs that may make the cost unstable.\n",
    "\n",
    "The output cost used for the baseline learning will be a weighted combination of both EMA and rollout baseline. More precisely:\n",
    "\n",
    "$L(baseline) \\leftarrow \\alpha L(\\pi_g) + (1 - \\alpha) M$\n",
    "\n",
    "Where $\\pi_g$ is the rollout baseline used by the algorithm; $\\alpha = \\frac{epoch + 1}{wp\\_n\\_epochs}$ is an dynamically-increasing constant from $0.0$ up to $1.0$. $\\alpha$ is not allowed to pass $1.0$, and when it does, warm up is deemed complete and only the baseline cost is used.\n",
    "\n",
    "```python\n",
    "def __init__(self, \n",
    "             model, \n",
    "             filename,\n",
    "             from_checkpoint=False,\n",
    "             path_to_checkpoint=None,\n",
    "             wp_n_epochs=1,\n",
    "             epoch=0,\n",
    "             num_samples=10000,\n",
    "             warmup_exp_beta=0.8,\n",
    "             embedding_dim=128,\n",
    "             graph_size=20\n",
    "             ): ...\n",
    "```\n",
    "\n",
    "| Parameter           | Description |\n",
    "| :---:               | :--- |\n",
    "| model               | Initial ML model to use as baseline |\n",
    "| filename            | Suffix for checkpoint name for the model (Keras). Model name template is `{path_to_checkpoint}/baseline_checkpoint_epoch_{epoch}_{filename}.h5`|\n",
    "| from_checkpoint     | Flag to use a saved checkpoint following the suffix provided. |\n",
    "| path_to_checkpoint  | Directory where to save baseline |\n",
    "| wp_n_epochs         | Number of warm up epochs |\n",
    "| epoch               | Starting epoch number |\n",
    "| num_samples         | Size of dataset generated for baseline. Used when deciding whether current model is statistically better than the baseline. |\n",
    "| warmup_exp_beta     | weight used during warm up. Balances incorporation of Exponential Moving Average and Rollout Baselines |\n",
    "| embedding_dim       | used for loading up model. |\n",
    "| graph_size          | Used for loading up model. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "026174c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/joseaguilar/coding/github/DynamicAttentionModel-VRP/attention_dynamic_model.py\u001b[0m(200)\u001b[0;36mget_log_likelihood\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    198 \u001b[0;31m        \u001b[0;31m# Get log_p corresponding to selected actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    199 \u001b[0;31m        \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 200 \u001b[0;31m        \u001b[0mlog_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_log_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    201 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    202 \u001b[0;31m        \u001b[0;31m# Calculate log_likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> print(_log_p.shape)\n",
      "(2, 15, 11)\n",
      "ipdb> print(a.shape)\n",
      "(2, 15)\n",
      "ipdb> print(tf.expand_dims(a, axis=-1))\n",
      "tf.Tensor(\n",
      "[[[10.]\n",
      "  [ 7.]\n",
      "  [ 1.]\n",
      "  [ 9.]\n",
      "  [ 0.]\n",
      "  [ 5.]\n",
      "  [ 3.]\n",
      "  [ 2.]\n",
      "  [ 0.]\n",
      "  [ 6.]\n",
      "  [ 4.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 8.]\n",
      "  [ 0.]]\n",
      "\n",
      " [[10.]\n",
      "  [ 5.]\n",
      "  [ 8.]\n",
      "  [ 0.]\n",
      "  [ 0.]\n",
      "  [ 2.]\n",
      "  [ 9.]\n",
      "  [ 4.]\n",
      "  [ 0.]\n",
      "  [ 1.]\n",
      "  [ 6.]\n",
      "  [ 3.]\n",
      "  [ 0.]\n",
      "  [ 7.]\n",
      "  [ 0.]]], shape=(2, 15, 1), dtype=float32)\n",
      "ipdb> print(a)\n",
      "tf.Tensor(\n",
      "[[10.  7.  1.  9.  0.  5.  3.  2.  0.  6.  4.  0.  0.  8.  0.]\n",
      " [10.  5.  8.  0.  0.  2.  9.  4.  0.  1.  6.  3.  0.  7.  0.]], shape=(2, 15), dtype=float32)\n",
      "ipdb> n\n",
      "> \u001b[0;32m/home/joseaguilar/coding/github/DynamicAttentionModel-VRP/attention_dynamic_model.py\u001b[0m(203)\u001b[0;36mget_log_likelihood\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    201 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    202 \u001b[0;31m        \u001b[0;31m# Calculate log_likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 203 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    204 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    205 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mget_projections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "--Return--\n",
      "<tf.Tensor: s...type=float32)>\n",
      "> \u001b[0;32m/home/joseaguilar/coding/github/DynamicAttentionModel-VRP/attention_dynamic_model.py\u001b[0m(203)\u001b[0;36mget_log_likelihood\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    201 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    202 \u001b[0;31m        \u001b[0;31m# Calculate log_likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 203 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    204 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    205 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mget_projections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/home/joseaguilar/coding/github/DynamicAttentionModel-VRP/attention_dynamic_model.py\u001b[0m(281)\u001b[0;36mcall\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    279 \u001b[0;31m        \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_log_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    280 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 281 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mreturn_pi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    282 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    283 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "> \u001b[0;32m/home/joseaguilar/coding/github/DynamicAttentionModel-VRP/attention_dynamic_model.py\u001b[0m(284)\u001b[0;36mcall\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    280 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    281 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mreturn_pi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    282 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    283 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 284 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> print(cost)\n",
      "tf.Tensor([7.4131165 8.5275   ], shape=(2,), dtype=float32)\n",
      "ipdb> exit()\n"
     ]
    }
   ],
   "source": [
    "from reinforce_baseline import RolloutBaseline\n",
    "from time import strftime, gmtime\n",
    "\n",
    "model              = model_amd\n",
    "graph_size         = 10\n",
    "filename           = 'VRP_{}_{}'.format(graph_size, strftime(\"%Y-%m-%d\", gmtime()))\n",
    "from_checkpoint    = False\n",
    "path_to_checkpoint = None\n",
    "wp_n_epochs        = 5\n",
    "epoch              = 0\n",
    "num_samples        = 10_000\n",
    "warmup_exp_beta    = 0.8\n",
    "embedding_dim      = embedding_dim\n",
    "\n",
    "\n",
    "baseline = RolloutBaseline(model             = model,\n",
    "                           filename          = filename,\n",
    "                           from_checkpoint   = from_checkpoint,\n",
    "                           path_to_checkpoint= path_to_checkpoint,\n",
    "                           wp_n_epochs       = wp_n_epochs,\n",
    "                           epoch             = epoch,\n",
    "                           num_samples       = num_samples,\n",
    "                           embedding_dim     = embedding_dim,\n",
    "                           graph_size        = graph_size\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d119b38",
   "metadata": {},
   "source": [
    "## Creating Problem Dataset\n",
    "\n",
    "Dataset generation is provided by the `utils.py` module. The recommended function to generate data is `create_data_on_disk`:\n",
    "\n",
    "```python\n",
    "def create_data_on_disk(\n",
    "    graph_size, \n",
    "    num_samples, \n",
    "    is_save=True, \n",
    "    filename=None, \n",
    "    is_return=False, \n",
    "    seed=1234): ...\n",
    "\n",
    "```\n",
    "\n",
    "| Parameter | Description|\n",
    "| :---:     | :---       |\n",
    "| graph_size  | Number of nodes to generate |\n",
    "| num_samples | Size of dataset |\n",
    "| is_save     | Flag for saving to disk |\n",
    "| filename    | Suffix of dataset: 'Validation\\_dataset\\_{filename}.pkl' |\n",
    "| is_return   | Whether to return dataset or not |\n",
    "| seed        | Seed for generation |\n",
    "\n",
    "Note that the data generated will use the TensorFlow API for datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d15af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_data_on_disk\n",
    "\n",
    "graph_size  = graph_size\n",
    "num_samples = 10_000\n",
    "is_save     = True\n",
    "filename    = filename\n",
    "is_return   = True\n",
    "seed        = 42\n",
    "\n",
    "validation_dataset = create_data_on_disk(graph_size =graph_size,\n",
    "                                         num_samples=num_samples,\n",
    "                                         is_save    =is_save,\n",
    "                                         filename   =filename,\n",
    "                                         is_return  =is_return,\n",
    "                                         seed       =seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97cb449",
   "metadata": {},
   "source": [
    "### Vizualization of output data\n",
    "\n",
    "Bellow we can appreciate the data generated with the TF dataset API. Also, a plot of the data can be seen in the graph bellow.\n",
    "\n",
    "#### Format of Data Generated\n",
    "\n",
    "The data generated uses Tensorflow's dataset API. This means that the data is generated in a batch-to-batch generation format. To access the data directly, use `next(data.batch(n).as_numpy_iterator)`. The data generated has the following structure:\n",
    "\n",
    "```\n",
    "batched_data[data type][batch's sample][xy data]\n",
    "```\n",
    "\n",
    "Here, `data type` represents the type of node that it is dealt with. In the case of the VRP data generator, this means whether we wish to look at the requesting/space nodes (value 1) or if we want to see the initial depot that the agents starts at (value 0). The `batch's sample` is just an index within the batch generated. Finally, `xy data` provides the type of node data to see. 0 is for x, 1 is for y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e631f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Grab first 6,000 datapoints. 6,000 is some random number.\n",
    "gen_data = next(validation_dataset.batch(6_000).as_numpy_iterator())\n",
    "\n",
    "# We select the first sample from the generated batch (first out of 6,000)\n",
    "sample   = 0\n",
    "\n",
    "# We collect all other nodes. Note: first index of gen_data [0] -> depot node, [1] -> other nodes\n",
    "graph    = pd.DataFrame(gen_data[1][sample], columns=['x', 'y'])\n",
    "\n",
    "# We collect the depot node. Add a label to identify it in table.\n",
    "depot = {\n",
    "    'x': gen_data[0][sample][0], \n",
    "    'y': gen_data[0][sample][1], \n",
    "    'type': 'depot'\n",
    "}\n",
    "# Label all other datapoints as nodes and add the already-labeled depot node\n",
    "graph = graph.assign(type='node').append(depot, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e69cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e5ad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=graph, x='x', y='y', hue='type', style='type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ea58c2",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "The developers provide a training function for orchestrating the training and rollout process of training.\n",
    "\n",
    "```python\n",
    "def train_model(optimizer,\n",
    "                model_tf,\n",
    "                baseline,\n",
    "                validation_dataset,\n",
    "                samples = 1280000,\n",
    "                batch = 128,\n",
    "                val_batch_size = 1000,\n",
    "                start_epoch = 0,\n",
    "                end_epoch = 5,\n",
    "                from_checkpoint = False,\n",
    "                grad_norm_clipping = 1.0,\n",
    "                batch_verbose = 1000,\n",
    "                graph_size = 20,\n",
    "                filename = None\n",
    "                ): ...\n",
    "```\n",
    "\n",
    "| Parameter          | Description |\n",
    "| :----------------: | :---------- |\n",
    "| optimizer          | Optimizer to be used for training |\n",
    "| model_tf           | Training model to use             |\n",
    "| baseline           | Initial baseline                  |\n",
    "| validation_dataset | Generated dataset for validation (used at the end) |\n",
    "| samples            | Number of samples to use for each learning epoch |\n",
    "| batch              | Size of batches for learning      |\n",
    "| val_batch_size     | Number of batches to use for validation (averaged out at the end for final score)|\n",
    "| start_epoch        | Initial epoch configuration       |\n",
    "| end_epoch          | Last epoch                        |\n",
    "| from_checkpoint    | Flag for loading checkpoint       |\n",
    "| grad_norm_clipping | Clipping/rescaling of gradients   |\n",
    "| batch_verbose      | Verbosity of output               |\n",
    "| graph_size         | Number of nodes for graph generated |\n",
    "| filename           | Suffix of saved model: `VRP_{graph_size}_{date}` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfa6904",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from train import train_model\n",
    "\n",
    "# Parameters\n",
    "optimizer          = optimizer\n",
    "model_tf           = model\n",
    "baseline           = baseline\n",
    "validation_dataset = validation_dataset\n",
    "samples            =  52_000 # Paper: 1_280_000\n",
    "batch              = 32\n",
    "val_batch_size     = 1_000 \n",
    "start_epoch        = 0\n",
    "end_epoch          = 50\n",
    "from_checkpoint    = False\n",
    "grad_norm_clipping = 1.0\n",
    "batch_verbose      = 1_000\n",
    "graph_size         = graph_size\n",
    "filename           = filename\n",
    "\n",
    "# Used for timing\n",
    "start_time = time.time()\n",
    "print(start_time)\n",
    "\n",
    "# Train...\n",
    "train_model(optimizer =optimizer,\n",
    "            model_tf = model_tf,\n",
    "            baseline = baseline,\n",
    "            validation_dataset = validation_dataset,\n",
    "            samples = samples,\n",
    "            batch = batch,\n",
    "            val_batch_size = val_batch_size,\n",
    "            start_epoch = start_epoch,\n",
    "            end_epoch = end_epoch,\n",
    "            from_checkpoint = from_checkpoint,\n",
    "            grad_norm_clipping = grad_norm_clipping,\n",
    "            batch_verbose = batch_verbose,\n",
    "            graph_size = graph_size,\n",
    "            filename = filename\n",
    "            )\n",
    "print(time.time() - start_time )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ab2229",
   "metadata": {},
   "source": [
    "## Saving a Model\n",
    "\n",
    "Since AM-D is a custom model, we can only save the weights on their own. Loading them requires creating a new AM-D model, set it up, and load the weights:\n",
    "\n",
    "```python\n",
    "loaded_model = AttentionDynamicModel(\n",
    "    embedding_dim  =embedding_dim,\n",
    "    n_encode_layers=n_encode_layers,\n",
    "    n_heads        =n_heads,\n",
    "    tanh_clipping  =tanh_clipping\n",
    ")\n",
    "\n",
    "# See Keras' API. the type *.ckp can be anything.\n",
    "loaded_model.load_weights('some_folder/some_checkpoint.ckp')\n",
    "\n",
    "# Don't forger to set the decoding type! Otherwise you get an error when trying to do inference!\n",
    "loaded_model.set_decode_type('greedy')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a51f092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes     = 20\n",
    "date      = 'oct_19'\n",
    "_iter     = end_epoch - start_epoch\n",
    "n_batches = samples\n",
    "batch_size = batch\n",
    "\n",
    "model_tf.save_weights(f\"checkpoints/AM-D_{date}_{nodes}_nodes_{_iter}_iter_{n_batches}_batches_{batch_size}_batch_size.ckp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ff261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
