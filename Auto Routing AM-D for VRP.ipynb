{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90450325",
   "metadata": {},
   "source": [
    "# Dynamic Attention Model (AM-D) Custom Execution\n",
    "\n",
    "This notebook contains code as I explore and test the implementation created by Eremeev and Pustynnikov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af2f5032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 16:56:08.072286: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from attention_dynamic_model import AttentionDynamicModel\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee64546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 16:56:38.899395: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-24 16:56:39.935996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-24 16:56:39.936642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5a312a",
   "metadata": {},
   "source": [
    "## Documentation on the AttentionDynamicModel class\n",
    "\n",
    "The AttentionDynamicModel class is the main model class that implements the AM-D model.\n",
    "\n",
    "### The constructor\n",
    "\n",
    "The constructor of the class will set up the basic attributes of the model as well as all the layers. For the encoder and decoder module, a separate class exists for the encoder, but the decoder is implemented inside this model.\n",
    "```python\n",
    "def __init__(self,\n",
    "             embedding_dim, \n",
    "             n_encode_layers=2, \n",
    "             n_heads=8, \n",
    "             tanh_clipping=10): ...\n",
    "```\n",
    "| Parameter | Description |\n",
    "|:---:|:---|\n",
    "| embedding_dim | The cardinality of the output produced by the embedding projection. This is used to set define the input to the encoder module as well as for the input of the decoder module. |\n",
    "| n_encode_layers | Number of encoder modules stacked |\n",
    "| n_heads | Number of heads used by both encoder and decoder attention modules.|\n",
    "| tanh_clipping | Value used for clipping the attention. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "324c878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-19 15:27:18.819641: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-19 15:27:18.821073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-19 15:27:18.821815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-19 15:27:18.822406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-19 15:27:25.218583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-19 15:27:25.219194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-19 15:27:25.219699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-19 15:27:25.220090: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-10-19 15:27:25.220346: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4817 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# AM-D Model Parameters\n",
    "embedding_dim   = 128\n",
    "n_encode_layers = 2\n",
    "n_heads         = 8\n",
    "tanh_clipping   = 10\n",
    "\n",
    "model_amd = AttentionDynamicModel(\n",
    "    embedding_dim  =embedding_dim,\n",
    "    n_encode_layers=n_encode_layers,\n",
    "    n_heads        =n_heads,\n",
    "    tanh_clipping  =tanh_clipping\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3280c7ee",
   "metadata": {},
   "source": [
    "#### Setting the Decode Style\n",
    "\n",
    "There are two types of decoding for AM-D:\n",
    "\n",
    "1. Greedy\n",
    "  - Greedy decoding will return the node with the highest probability from the decoder output.\n",
    "2. Sampling\n",
    "  - Sampling decoding will return a random node following the random distribution generated by the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47bd9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_amd.set_decode_type('sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17564c7c",
   "metadata": {},
   "source": [
    "## Selecting Optimizer\n",
    "\n",
    "We have to define an optimizer for the model. See keras' options for this. There are many types to choose from.\n",
    "\n",
    "### Adam\n",
    "```python\n",
    "tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name=\"Adam\",\n",
    "    **kwargs\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3273aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Optimizer Parameters\n",
    "learning_rate = 0.0001\n",
    "beta_1        = 0.9\n",
    "beta_2        = 0.999\n",
    "epsilon       = 1e-07\n",
    "amsgrad       = False\n",
    "name          = \"Adam\"\n",
    "\n",
    "\n",
    "optimizer = Adam(\n",
    "    learning_rate=learning_rate,\n",
    "    beta_1=beta_1,\n",
    "    beta_2=beta_2,\n",
    "    epsilon=epsilon,\n",
    "    amsgrad=amsgrad,\n",
    "    name=name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4869c55a",
   "metadata": {},
   "source": [
    "## Creating a Baseline for More Efficient Reinforcement Learning\n",
    "\n",
    "The AM-D model uses a baseline to help improve the stability of learning. During regular reinforcement learning, it can be challenging to distinguish between actions when the reward obtained may vary based on the state the agent was found on. For example, a set of actions may produce a reward that could be different that the reward obtained starting in a different state that leads to the same end state. This means that the reward variance is high, and it can be hard to compare high reward actions when the initial state is variant. \n",
    "\n",
    "To solve this problem, a baseline can be used. In the past, baselines in RL would be a constant value that helps distinguish states based on a \"neutral\" state that provides information on whether an action is \"better or worse.\" Variance in RL tends to be dependent on the state an agent is found, so we require a dynamic baseline that provides a \"neutral\" baseline to use for comparing the rewards and reach a referendum easier on what actions are better or worse. There are many different baselines, but for AM-D the best traines AM-D policy is used. If better actions are found that produce better reward, then, the baseline can help see these better actions, based on the best actions learned so far.\n",
    "\n",
    "### Rollout Baseline\n",
    "\n",
    "The Rollout baseline is a type of baseline that uses a ML model that produces the best learned actions so far. Whenever the learned model outperforms the baseline (statistically speaking with T-test) then, the baseline is replaced with the learned model.\n",
    "\n",
    "__For the AM-D model, a warm up stage can be used for more stable convergance.__ The way this works is that a combination of exponential moving average baseline is used together with the rolling baseline. At the very begining of learning, the policy for the rollout baseline may be too bad to give meaningful baseline costs. To solve this, we can first rely on exponential moving average that utilizes the mean cost obtained by the training model and the average cost is over time is updated by weighting recently-obtained costs higher than previous ones. This also helps in getting through the initial \"row\" of bad costs obtained by exploration. The Exponential Moving Average (EMA) equation is the following:\n",
    "\n",
    "$M \\leftarrow \\beta M + (1-\\beta) L(\\pi)$\n",
    "\n",
    "Where $M$ is the moving average and $\\beta$ is the weight factor on the importance of previous obtained costs with respect to recent ones. As $\\beta$ approaches 0, recent costs are more important and previous costs are forgoten faster. as $\\beta$ apptoaches 1.0, previous costs are not as forgoten and remain important to recent average cost. Finding a good balance is important because low $\\beta$ will make the average cost be too unstable but high $\\beta$ will make the cost depend too much on early outlier costs that may make the cost unstable.\n",
    "\n",
    "The output cost used for the baseline learning will be a weighted combination of both EMA and rollout baseline. More precisely:\n",
    "\n",
    "$L(baseline) \\leftarrow \\alpha L(\\pi_g) + (1 - \\alpha) M$\n",
    "\n",
    "Where $\\pi_g$ is the rollout baseline used by the algorithm; $\\alpha = \\frac{epoch + 1}{wp\\_n\\_epochs}$ is an dynamically-increasing constant from $0.0$ up to $1.0$. $\\alpha$ is not allowed to pass $1.0$, and when it does, warm up is deemed complete and only the baseline cost is used.\n",
    "\n",
    "```python\n",
    "def __init__(self, \n",
    "             model, \n",
    "             filename,\n",
    "             from_checkpoint=False,\n",
    "             path_to_checkpoint=None,\n",
    "             wp_n_epochs=1,\n",
    "             epoch=0,\n",
    "             num_samples=10000,\n",
    "             warmup_exp_beta=0.8,\n",
    "             embedding_dim=128,\n",
    "             graph_size=20\n",
    "             ): ...\n",
    "```\n",
    "\n",
    "| Parameter           | Description |\n",
    "| :---:               | :--- |\n",
    "| model               | Initial ML model to use as baseline |\n",
    "| filename            | Suffix for checkpoint name for the model (Keras). Model name template is `{path_to_checkpoint}/baseline_checkpoint_epoch_{epoch}_{filename}.h5`|\n",
    "| from_checkpoint     | Flag to use a saved checkpoint following the suffix provided. |\n",
    "| path_to_checkpoint  | Directory where to save baseline |\n",
    "| wp_n_epochs         | Number of warm up epochs |\n",
    "| epoch               | Starting epoch number |\n",
    "| num_samples         | Size of dataset generated for baseline. Used when deciding whether current model is statistically better than the baseline. |\n",
    "| warmup_exp_beta     | weight used during warm up. Balances incorporation of Exponential Moving Average and Rollout Baselines |\n",
    "| embedding_dim       | used for loading up model. |\n",
    "| graph_size          | Used for loading up model. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb9455ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating baseline model on baseline dataset (epoch = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████| 10/10 [00:21<00:00,  2.11s/it]\n"
     ]
    }
   ],
   "source": [
    "from reinforce_baseline import RolloutBaseline\n",
    "from time import strftime, gmtime\n",
    "\n",
    "model              = model_amd\n",
    "graph_size         = 20\n",
    "filename           = 'VRP_{}_{}'.format(graph_size, strftime(\"%Y-%m-%d\", gmtime()))\n",
    "from_checkpoint    = False\n",
    "path_to_checkpoint = None\n",
    "wp_n_epochs        = 5\n",
    "epoch              = 0\n",
    "num_samples        = 10_000\n",
    "warmup_exp_beta    = 0.8\n",
    "embedding_dim      = embedding_dim\n",
    "\n",
    "\n",
    "baseline = RolloutBaseline(model             = model,\n",
    "                           filename          = filename,\n",
    "                           from_checkpoint   = from_checkpoint,\n",
    "                           path_to_checkpoint= path_to_checkpoint,\n",
    "                           wp_n_epochs       = wp_n_epochs,\n",
    "                           epoch             = epoch,\n",
    "                           num_samples       = num_samples,\n",
    "                           embedding_dim     = embedding_dim,\n",
    "                           graph_size        = graph_size\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ae1d45",
   "metadata": {},
   "source": [
    "## Creating Problem Dataset\n",
    "\n",
    "Dataset generation is provided by the `utils.py` module. The recommended function to generate data is `create_data_on_disk`:\n",
    "\n",
    "```python\n",
    "def create_data_on_disk(\n",
    "    graph_size, \n",
    "    num_samples, \n",
    "    is_save=True, \n",
    "    filename=None, \n",
    "    is_return=False, \n",
    "    seed=1234): ...\n",
    "\n",
    "```\n",
    "\n",
    "| Parameter | Description|\n",
    "| :---:     | :---       |\n",
    "| graph_size  | Number of nodes to generate |\n",
    "| num_samples | Size of dataset |\n",
    "| is_save     | Flag for saving to disk |\n",
    "| filename    | Suffix of dataset: 'Validation\\_dataset\\_{filename}.pkl' |\n",
    "| is_return   | Whether to return dataset or not |\n",
    "| seed        | Seed for generation |\n",
    "\n",
    "Note that the data generated will use the TensorFlow API for datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15219254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_data_on_disk\n",
    "\n",
    "graph_size  = graph_size\n",
    "num_samples = 10_000\n",
    "is_save     = True\n",
    "filename    = filename\n",
    "is_return   = True\n",
    "seed        = 42\n",
    "\n",
    "validation_dataset = create_data_on_disk(graph_size =graph_size,\n",
    "                                         num_samples=num_samples,\n",
    "                                         is_save    =is_save,\n",
    "                                         filename   =filename,\n",
    "                                         is_return  =is_return,\n",
    "                                         seed       =seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957e5e95",
   "metadata": {},
   "source": [
    "### Vizualization of output data\n",
    "\n",
    "Bellow we can appreciate the data generated with the TF dataset API. Also, a plot of the data can be seen in the graph bellow.\n",
    "\n",
    "#### Format of Data Generated\n",
    "\n",
    "The data generated uses Tensorflow's dataset API. This means that the data is generated in a batch-to-batch generation format. To access the data directly, use `next(data.batch(n).as_numpy_iterator)`. The data generated has the following structure:\n",
    "\n",
    "```\n",
    "batched_data[data type][batch's sample][xy data]\n",
    "```\n",
    "\n",
    "Here, `data type` represents the type of node that it is dealt with. In the case of the VRP data generator, this means whether we wish to look at the requesting/space nodes (value 1) or if we want to see the initial depot that the agents starts at (value 0). The `batch's sample` is just an index within the batch generated. Finally, `xy data` provides the type of node data to see. 0 is for x, 1 is for y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2527f478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75366/106837068.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  graph = graph.assign(type='node').append(goal, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.090576</td>\n",
       "      <td>0.105941</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.672503</td>\n",
       "      <td>0.656092</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.402797</td>\n",
       "      <td>0.798440</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.893440</td>\n",
       "      <td>0.426028</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260078</td>\n",
       "      <td>0.359273</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.652982</td>\n",
       "      <td>0.425485</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.080519</td>\n",
       "      <td>0.855694</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.147657</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.521012</td>\n",
       "      <td>0.173180</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.042330</td>\n",
       "      <td>0.255430</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.056516</td>\n",
       "      <td>0.140128</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.484007</td>\n",
       "      <td>0.264015</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.139997</td>\n",
       "      <td>0.855501</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.504407</td>\n",
       "      <td>0.060363</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.184143</td>\n",
       "      <td>0.334701</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.951709</td>\n",
       "      <td>0.101621</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.515714</td>\n",
       "      <td>0.946507</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.889182</td>\n",
       "      <td>0.069698</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.350460</td>\n",
       "      <td>0.026653</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.699666</td>\n",
       "      <td>0.429203</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.952271</td>\n",
       "      <td>0.677408</td>\n",
       "      <td>depot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x         y   type\n",
       "0   0.090576  0.105941   node\n",
       "1   0.672503  0.656092   node\n",
       "2   0.402797  0.798440   node\n",
       "3   0.893440  0.426028   node\n",
       "4   0.260078  0.359273   node\n",
       "5   0.652982  0.425485   node\n",
       "6   0.080519  0.855694   node\n",
       "7   0.147657  0.004048   node\n",
       "8   0.521012  0.173180   node\n",
       "9   0.042330  0.255430   node\n",
       "10  0.056516  0.140128   node\n",
       "11  0.484007  0.264015   node\n",
       "12  0.139997  0.855501   node\n",
       "13  0.504407  0.060363   node\n",
       "14  0.184143  0.334701   node\n",
       "15  0.951709  0.101621   node\n",
       "16  0.515714  0.946507   node\n",
       "17  0.889182  0.069698   node\n",
       "18  0.350460  0.026653   node\n",
       "19  0.699666  0.429203   node\n",
       "20  0.952271  0.677408  depot"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Grab first 6,000 datapoints. 6,000 is some random number.\n",
    "gen_data = next(validation_dataset.batch(6_000).as_numpy_iterator())\n",
    "\n",
    "# We select the first sample from the generated batch (first out of 6,000)\n",
    "sample   = 0\n",
    "\n",
    "# We collect all other nodes. Note: first index of gen_data [0] -> depot node, [1] -> other nodes\n",
    "graph    = pd.DataFrame(gen_data[1][sample], columns=['x', 'y'])\n",
    "\n",
    "# We collect the depot node. Add a label to identify it in table.\n",
    "depot = {\n",
    "    'x': gen_data[0][sample][0], \n",
    "    'y': gen_data[0][sample][1], \n",
    "    'type': 'depot'\n",
    "}\n",
    "# Label all other datapoints as nodes and add the already-labeled depot node\n",
    "graph = graph.assign(type='node').append(depot, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5078370",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89154ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='x', ylabel='y'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(data=graph, x='x', y='y', hue='type', style='type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc391a9",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "The developers provide a training function for orchestrating the training and rollout process of training.\n",
    "\n",
    "```python\n",
    "def train_model(optimizer,\n",
    "                model_tf,\n",
    "                baseline,\n",
    "                validation_dataset,\n",
    "                samples = 1280000,\n",
    "                batch = 128,\n",
    "                val_batch_size = 1000,\n",
    "                start_epoch = 0,\n",
    "                end_epoch = 5,\n",
    "                from_checkpoint = False,\n",
    "                grad_norm_clipping = 1.0,\n",
    "                batch_verbose = 1000,\n",
    "                graph_size = 20,\n",
    "                filename = None\n",
    "                ): ...\n",
    "```\n",
    "\n",
    "| Parameter          | Description |\n",
    "| :----------------: | :---------- |\n",
    "| optimizer          | Optimizer to be used for training |\n",
    "| model_tf           | Training model to use             |\n",
    "| baseline           | Initial baseline                  |\n",
    "| validation_dataset | Generated dataset for validation (used at the end) |\n",
    "| samples            | Number of samples to use for each learning epoch |\n",
    "| batch              | Size of batches for learning      |\n",
    "| val_batch_size     | Number of batches to use for validation (averaged out at the end for final score)|\n",
    "| start_epoch        | Initial epoch configuration       |\n",
    "| end_epoch          | Last epoch                        |\n",
    "| from_checkpoint    | Flag for loading checkpoint       |\n",
    "| grad_norm_clipping | Clipping/rescaling of gradients   |\n",
    "| batch_verbose      | Verbosity of output               |\n",
    "| graph_size         | Number of nodes for graph generated |\n",
    "| filename           | Suffix of saved model: `VRP_{graph_size}_{date}` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e8fbe54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1666211299.4284105\n",
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 0: 1it [00:02,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 8.752344131469727, clipped_norm = 0.9999999403953552\n",
      "Epoch 0 (batch = 0): Loss: 0.4247629642486572: Cost: 13.520952224731445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 0: 1001it [17:52,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 10.049118995666504, clipped_norm = 1.0\n",
      "Epoch 0 (batch = 1000): Loss: 0.12831465899944305: Cost: 9.994102478027344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 0: 1625it [28:52,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████| 10/10 [00:06<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 candidate mean 8.094402313232422, baseline epoch 0 mean 13.717153549194336, difference -5.622751235961914\n",
      "p-value: 0.0\n",
      "Update baseline\n",
      "Evaluating baseline model on baseline dataset (epoch = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████| 10/10 [00:06<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha was updated to 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 8.113699913024902\n",
      "2022-10-19 15:58:16 Epoch 0: Loss: -0.05598825216293335: Cost: 9.48063850402832\n",
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 1: 1it [00:01,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 13.598526954650879, clipped_norm = 1.0000001192092896\n",
      "Epoch 1 (batch = 0): Loss: -0.7262731790542603: Cost: 8.3829345703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 1: 1001it [25:27,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 16.113672256469727, clipped_norm = 1.0\n",
      "Epoch 1 (batch = 1000): Loss: -0.3159732222557068: Cost: 8.044578552246094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 1: 1625it [41:16,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████| 10/10 [00:06<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 candidate mean 7.510475158691406, baseline epoch 1 mean 8.135576248168945, difference -0.6251010894775391\n",
      "p-value: 0.0\n",
      "Update baseline\n",
      "Evaluating baseline model on baseline dataset (epoch = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████| 10/10 [00:06<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha was updated to 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████| 10/10 [00:10<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 7.506999969482422\n",
      "2022-10-19 16:40:38 Epoch 1: Loss: -0.11084447056055069: Cost: 7.942144393920898\n",
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 2: 1it [00:01,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 11.935769081115723, clipped_norm = 0.9999999403953552\n",
      "Epoch 2 (batch = 0): Loss: -1.5577688217163086: Cost: 7.918816089630127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 2: 1001it [26:37,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 12.061907768249512, clipped_norm = 1.0\n",
      "Epoch 2 (batch = 1000): Loss: -0.3782106935977936: Cost: 7.543488025665283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 2: 1625it [43:59,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████| 10/10 [00:06<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 candidate mean 7.255475044250488, baseline epoch 2 mean 7.508060932159424, difference -0.25258588790893555\n",
      "p-value: 6.410203039898151e-285\n",
      "Update baseline\n",
      "Evaluating baseline model on baseline dataset (epoch = 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████| 10/10 [00:06<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha was updated to 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████| 10/10 [00:06<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 7.246200084686279\n",
      "2022-10-19 17:25:40 Epoch 2: Loss: -0.2450256198644638: Cost: 7.486406326293945\n",
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 3: 1it [00:01,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 11.206875801086426, clipped_norm = 0.9999999403953552\n",
      "Epoch 3 (batch = 0): Loss: -0.7285658121109009: Cost: 7.298762321472168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 3: 1001it [28:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 13.638163566589355, clipped_norm = 0.9999999403953552\n",
      "Epoch 3 (batch = 1000): Loss: -0.4768742620944977: Cost: 7.290483474731445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 3: 1625it [45:54,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████| 10/10 [00:07<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 candidate mean 7.113739013671875, baseline epoch 3 mean 7.257171154022217, difference -0.1434321403503418\n",
      "p-value: 3.837320383133212e-129\n",
      "Update baseline\n",
      "Evaluating baseline model on baseline dataset (epoch = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████| 10/10 [00:07<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha was updated to 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████| 10/10 [00:06<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 7.110099792480469\n",
      "2022-10-19 18:12:38 Epoch 3: Loss: -0.4190031588077545: Cost: 7.281337261199951\n",
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 4: 1it [00:01,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 11.672294616699219, clipped_norm = 1.0\n",
      "Epoch 4 (batch = 0): Loss: -1.3833853006362915: Cost: 7.638968467712402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 4: 183it [05:34,  1.83s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(start_time)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_tf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43mval_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43mend_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mend_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfrom_checkpoint\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfrom_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgrad_norm_clipping\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgrad_norm_clipping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_verbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgraph_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgraph_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time )\n",
      "File \u001b[0;32m~/coding/github/DynamicAttentionModel-VRP/train.py:84\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(optimizer, model_tf, baseline, validation_dataset, samples, batch, val_batch_size, start_epoch, end_epoch, from_checkpoint, grad_norm_clipping, batch_verbose, graph_size, filename)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent decode type: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_tf\u001b[38;5;241m.\u001b[39mdecode_type))\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_batch, x_batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(data\u001b[38;5;241m.\u001b[39mbatch(batch)), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch calculation at epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch)):\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# Optimize the model\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     loss_value, cost_val, grads \u001b[38;5;241m=\u001b[39m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# Clip gradients by grad_norm_clipping\u001b[39;00m\n\u001b[1;32m     87\u001b[0m     init_global_norm \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mglobal_norm(grads)\n",
      "File \u001b[0;32m~/coding/github/DynamicAttentionModel-VRP/train.py:53\u001b[0m, in \u001b[0;36mtrain_model.<locals>.grad\u001b[0;34m(model, inputs, baseline, num_batch)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m\"\"\"Calculate gradients\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 53\u001b[0m     loss, cost \u001b[38;5;241m=\u001b[39m \u001b[43mrein_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, cost, tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n",
      "File \u001b[0;32m~/coding/github/DynamicAttentionModel-VRP/train.py:41\u001b[0m, in \u001b[0;36mtrain_model.<locals>.rein_loss\u001b[0;34m(model, inputs, baseline, num_batch)\u001b[0m\n\u001b[1;32m     36\u001b[0m cost, log_likelihood \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Evaluate baseline\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# For first wp_n_epochs we take the combination of baseline and ema for previous batches\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# after that we take a slice of precomputed baseline values\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m bl_val \u001b[38;5;241m=\u001b[39m bl_vals[num_batch] \u001b[38;5;28;01mif\u001b[39;00m bl_vals \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mbaseline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m bl_val \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstop_gradient(bl_val)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n",
      "File \u001b[0;32m~/coding/github/DynamicAttentionModel-VRP/reinforce_baseline.py:152\u001b[0m, in \u001b[0;36mRolloutBaseline.eval\u001b[0;34m(self, batch, cost)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     v_ema \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m--> 152\u001b[0m v_b, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m v_b \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstop_gradient(v_b)\n\u001b[1;32m    155\u001b[0m v_ema \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstop_gradient(v_ema)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/keras/engine/training.py:557\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    555\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[0;32m--> 557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/keras/engine/base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1096\u001b[0m ):\n\u001b[0;32m-> 1097\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/coding/github/DynamicAttentionModel-VRP/attention_dynamic_model.py:278\u001b[0m, in \u001b[0;36mAttentionDynamicModel.call\u001b[0;34m(self, inputs, return_pi)\u001b[0m\n\u001b[1;32m    274\u001b[0m _log_p, pi \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstack(outputs, \u001b[38;5;241m1\u001b[39m), tf\u001b[38;5;241m.\u001b[39mcast(tf\u001b[38;5;241m.\u001b[39mstack(sequences, \u001b[38;5;241m1\u001b[39m), tf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    276\u001b[0m cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem\u001b[38;5;241m.\u001b[39mget_costs(inputs, pi)\n\u001b[0;32m--> 278\u001b[0m ll \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_log_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_log_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_pi:\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cost, ll, pi\n",
      "File \u001b[0;32m~/coding/github/DynamicAttentionModel-VRP/attention_dynamic_model.py:199\u001b[0m, in \u001b[0;36mAttentionDynamicModel.get_log_likelihood\u001b[0;34m(self, _log_p, a)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_log_likelihood\u001b[39m(\u001b[38;5;28mself\u001b[39m, _log_p, a):\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m     \u001b[38;5;66;03m# Get log_p corresponding to selected actions\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     log_p \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_log_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# Calculate log_likelihood\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mreduce_sum(log_p,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:5710\u001b[0m, in \u001b[0;36mgather_nd_v2\u001b[0;34m(params, indices, batch_dims, name)\u001b[0m\n\u001b[1;32m   5707\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgather_nd\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m   5708\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m   5709\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgather_nd_v2\u001b[39m(params, indices, batch_dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 5710\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgather_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_dims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:5704\u001b[0m, in \u001b[0;36mgather_nd\u001b[0;34m(params, indices, name, batch_dims)\u001b[0m\n\u001b[1;32m   5702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gen_array_ops\u001b[38;5;241m.\u001b[39mgather_nd(params, indices, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m   5703\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 5704\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbatch_gather_nd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:5762\u001b[0m, in \u001b[0;36mbatch_gather_nd\u001b[0;34m(params, indices, batch_dims, name)\u001b[0m\n\u001b[1;32m   5757\u001b[0m batch_dim_list \u001b[38;5;241m=\u001b[39m unstack(batch_shape, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   5758\u001b[0m dim_ranges \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   5759\u001b[0m     gen_math_ops\u001b[38;5;241m.\u001b[39mcast(gen_math_ops\u001b[38;5;241m.\u001b[39m_range(\u001b[38;5;241m0\u001b[39m, x, \u001b[38;5;241m1\u001b[39m), indices\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m   5760\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batch_dim_list\n\u001b[1;32m   5761\u001b[0m ]\n\u001b[0;32m-> 5762\u001b[0m mesh_list \u001b[38;5;241m=\u001b[39m \u001b[43mmeshgrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdim_ranges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mij\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m dim_ranges \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m   5763\u001b[0m \u001b[38;5;66;03m# Then we flatten and stack the tensors to form a (B1.B2) by 2 matrix.\u001b[39;00m\n\u001b[1;32m   5764\u001b[0m flat_list \u001b[38;5;241m=\u001b[39m [reshape(x, shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m mesh_list]\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:3772\u001b[0m, in \u001b[0;36mmeshgrid\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3769\u001b[0m   shapes[\u001b[38;5;241m0\u001b[39m], shapes[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m shapes[\u001b[38;5;241m1\u001b[39m], shapes[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   3771\u001b[0m \u001b[38;5;66;03m# TODO(nolivia): improve performance with a broadcast\u001b[39;00m\n\u001b[0;32m-> 3772\u001b[0m mult_fact \u001b[38;5;241m=\u001b[39m \u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3773\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [x \u001b[38;5;241m*\u001b[39m mult_fact \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output]\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:3282\u001b[0m, in \u001b[0;36mones\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   3278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m   3280\u001b[0m   \u001b[38;5;66;03m# Go through tensor shapes to get int64-if-needed semantics\u001b[39;00m\n\u001b[1;32m   3281\u001b[0m   shape \u001b[38;5;241m=\u001b[39m constant_op\u001b[38;5;241m.\u001b[39m_tensor_shape_tensor_conversion_function(\n\u001b[0;32m-> 3282\u001b[0m       \u001b[43mtensor_shape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensorShape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   3283\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   3284\u001b[0m   \u001b[38;5;66;03m# Happens when shape is a list with tensor elements\u001b[39;00m\n\u001b[1;32m   3285\u001b[0m   shape \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(shape, dtype\u001b[38;5;241m=\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mint32)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py:776\u001b[0m, in \u001b[0;36mTensorShape.__init__\u001b[0;34m(self, dims)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;124;03m\"\"\"Creates a new TensorShape with the given dimensions.\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \n\u001b[1;32m    769\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;124;03m  TypeError: If dims cannot be converted to a list of dimensions.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dims, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):  \u001b[38;5;66;03m# Most common case.\u001b[39;00m\n\u001b[0;32m--> 776\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mas_dimension\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train import train_model\n",
    "\n",
    "# Parameters\n",
    "optimizer          = optimizer\n",
    "model_tf           = model\n",
    "baseline           = baseline\n",
    "validation_dataset = validation_dataset\n",
    "samples            =  52_000 # Paper: 1_280_000\n",
    "batch              = 32\n",
    "val_batch_size     = 1_000 \n",
    "start_epoch        = 0\n",
    "end_epoch          = 50\n",
    "from_checkpoint    = False\n",
    "grad_norm_clipping = 1.0\n",
    "batch_verbose      = 1_000\n",
    "graph_size         = graph_size\n",
    "filename           = filename\n",
    "\n",
    "# Used for timing\n",
    "start_time = time.time()\n",
    "print(start_time)\n",
    "\n",
    "# Train...\n",
    "train_model(optimizer =optimizer,\n",
    "            model_tf = model_tf,\n",
    "            baseline = baseline,\n",
    "            validation_dataset = validation_dataset,\n",
    "            samples = samples,\n",
    "            batch = batch,\n",
    "            val_batch_size = val_batch_size,\n",
    "            start_epoch = start_epoch,\n",
    "            end_epoch = end_epoch,\n",
    "            from_checkpoint = from_checkpoint,\n",
    "            grad_norm_clipping = grad_norm_clipping,\n",
    "            batch_verbose = batch_verbose,\n",
    "            graph_size = graph_size,\n",
    "            filename = filename\n",
    "            )\n",
    "print(time.time() - start_time )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb49cae2",
   "metadata": {},
   "source": [
    "## Saving a Model\n",
    "\n",
    "Since AM-D is a custom model, we can only save the weights on their own. Loading them requires creating a new AM-D model, set it up, and load the weights:\n",
    "\n",
    "```python\n",
    "loaded_model = AttentionDynamicModel(\n",
    "    embedding_dim  =embedding_dim,\n",
    "    n_encode_layers=n_encode_layers,\n",
    "    n_heads        =n_heads,\n",
    "    tanh_clipping  =tanh_clipping\n",
    ")\n",
    "\n",
    "# See Keras' API. the type *.ckp can be anything.\n",
    "loaded_model.load_weights('some_folder/some_checkpoint.ckp')\n",
    "\n",
    "# Don't forger to set the decoding type! Otherwise you get an error when trying to do inference!\n",
    "loaded_model.set_decode_type('greedy')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70be4eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes     = 20\n",
    "date      = 'oct_19'\n",
    "_iter     = end_epoch - start_epoch\n",
    "n_batches = samples\n",
    "batch_size = batch\n",
    "\n",
    "model_tf.save_weights(f\"checkpoints/AM-D_{date}_{nodes}_nodes_{_iter}_iter_{n_batches}_batches_{batch_size}_batch_size.ckp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae919f42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
