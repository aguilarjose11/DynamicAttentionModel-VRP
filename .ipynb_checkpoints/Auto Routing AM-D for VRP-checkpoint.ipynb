{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90450325",
   "metadata": {},
   "source": [
    "# Dynamic Attention Model (AM-D) Custom Execution\n",
    "\n",
    "This notebook contains code as I explore and test the implementation created by Eremeev and Pustynnikov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af2f5032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 11:50:26.582012: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from attention_dynamic_model import AttentionDynamicModel\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee64546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "env: TF_GPU_ALLOCATOR=cuda_malloc_async\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 11:50:27.979772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-17 11:50:28.011420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-17 11:50:28.011581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "%env TF_GPU_ALLOCATOR=cuda_malloc_async"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5a312a",
   "metadata": {},
   "source": [
    "## Documentation on the AttentionDynamicModel class\n",
    "\n",
    "The AttentionDynamicModel class is the main model class that implements the AM-D model.\n",
    "\n",
    "### The constructor\n",
    "\n",
    "The constructor of the class will set up the basic attributes of the model as well as all the layers. For the encoder and decoder module, a separate class exists for the encoder, but the decoder is implemented inside this model.\n",
    "```python\n",
    "def __init__(self,\n",
    "             embedding_dim, \n",
    "             n_encode_layers=2, \n",
    "             n_heads=8, \n",
    "             tanh_clipping=10): ...\n",
    "```\n",
    "| Parameter | Description |\n",
    "|:---:|:---|\n",
    "| embedding_dim | The cardinality of the output produced by the embedding projection. This is used to set define the input to the encoder module as well as for the input of the decoder module. |\n",
    "| n_encode_layers | Number of encoder modules stacked |\n",
    "| n_heads | Number of heads used by both encoder and decoder attention modules.|\n",
    "| tanh_clipping | Value used for clipping the attention. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "324c878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 11:50:29.108809: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-17 11:50:29.109342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-17 11:50:29.109604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-17 11:50:29.109793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-17 11:50:29.575185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-17 11:50:29.575356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-17 11:50:29.575474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-17 11:50:29.575553: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-10-17 11:50:29.575629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 776 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# AM-D Model Parameters\n",
    "embedding_dim   = 128\n",
    "n_encode_layers = 2\n",
    "n_heads         = 8\n",
    "tanh_clipping   = 10\n",
    "\n",
    "model_amd = AttentionDynamicModel(\n",
    "    embedding_dim  =embedding_dim,\n",
    "    n_encode_layers=n_encode_layers,\n",
    "    n_heads        =n_heads,\n",
    "    tanh_clipping  =tanh_clipping\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3280c7ee",
   "metadata": {},
   "source": [
    "#### Setting the Decode Style\n",
    "\n",
    "There are two types of decoding for AM-D:\n",
    "\n",
    "1. Greedy\n",
    "  - Greedy decoding will return the node with the highest probability from the decoder output.\n",
    "2. Sampling\n",
    "  - Sampling decoding will return a random node following the random distribution generated by the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47bd9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_amd.set_decode_type('sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17564c7c",
   "metadata": {},
   "source": [
    "### Selecting Optimizer\n",
    "\n",
    "We have to define an optimizer for the model. See keras' options for this. There are many types to choose from.\n",
    "\n",
    "#### Adam\n",
    "```python\n",
    "tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name=\"Adam\",\n",
    "    **kwargs\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3273aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Optimizer Parameters\n",
    "learning_rate = 0.0001\n",
    "beta_1        = 0.9\n",
    "beta_2        = 0.999\n",
    "epsilon       = 1e-07\n",
    "amsgrad       = False\n",
    "name          = \"Adam\"\n",
    "\n",
    "\n",
    "optimizer = Adam(\n",
    "    learning_rate=learning_rate,\n",
    "    beta_1=beta_1,\n",
    "    beta_2=beta_2,\n",
    "    epsilon=epsilon,\n",
    "    amsgrad=amsgrad,\n",
    "    name=name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4869c55a",
   "metadata": {},
   "source": [
    "### Creating a Baseline for More Efficient Reinforcement Learning\n",
    "\n",
    "The AM-D model uses a baseline to help improve the stability of learning. During regular reinforcement learning, it can be challenging to distinguish between actions when the reward obtained may vary based on the state the agent was found on. For example, a set of actions may produce a reward that could be different that the reward obtained starting in a different state that leads to the same end state. This means that the reward variance is high, and it can be hard to compare high reward actions when the initial state is variant. \n",
    "\n",
    "To solve this problem, a baseline can be used. In the past, baselines in RL would be a constant value that helps distinguish states based on a \"neutral\" state that provides information on whether an action is \"better or worse.\" Variance in RL tends to be dependent on the state an agent is found, so we require a dynamic baseline that provides a \"neutral\" baseline to use for comparing the rewards and reach a referendum easier on what actions are better or worse. There are many different baselines, but for AM-D the best traines AM-D policy is used. If better actions are found that produce better reward, then, the baseline can help see these better actions, based on the best actions learned so far.\n",
    "\n",
    "#### Rollout Baseline\n",
    "\n",
    "The Rollout baseline is a type of baseline that uses a ML model that produces the best learned actions so far. Whenever the learned model outperforms the baseline (statistically speaking with T-test) then, the baseline is replaced with the learned model.\n",
    "\n",
    "__For the AM-D model, a warm up stage can be used for more stable convergance.__ The way this works is that a combination of exponential moving average baseline is used together with the rolling baseline. At the very begining of learning, the policy for the rollout baseline may be too bad to give meaningful baseline costs. To solve this, we can first rely on exponential moving average that utilizes the mean cost obtained by the training model and the average cost is over time is updated by weighting recently-obtained costs higher than previous ones. This also helps in getting through the initial \"row\" of bad costs obtained by exploration. The Exponential Moving Average (EMA) equation is the following:\n",
    "\n",
    "$M \\leftarrow \\beta M + (1-\\beta) L(\\pi)$\n",
    "\n",
    "Where $M$ is the moving average and $\\beta$ is the weight factor on the importance of previous obtained costs with respect to recent ones. As $\\beta$ approaches 0, recent costs are more important and previous costs are forgoten faster. as $\\beta$ apptoaches 1.0, previous costs are not as forgoten and remain important to recent average cost. Finding a good balance is important because low $\\beta$ will make the average cost be too unstable but high $\\beta$ will make the cost depend too much on early outlier costs that may make the cost unstable.\n",
    "\n",
    "The output cost used for the baseline learning will be a weighted combination of both EMA and rollout baseline. More precisely:\n",
    "\n",
    "$L(baseline) \\leftarrow \\alpha L(\\pi_g) + (1 - \\alpha) M$\n",
    "\n",
    "Where $\\pi_g$ is the rollout baseline used by the algorithm; $\\alpha = \\frac{epoch + 1}{wp\\_n\\_epochs}$ is an dynamically-increasing constant from $0.0$ up to $1.0$. $\\alpha$ is not allowed to pass $1.0$, and when it does, warm up is deemed complete and only the baseline cost is used.\n",
    "\n",
    "```python\n",
    "def __init__(self, \n",
    "             model, \n",
    "             filename,\n",
    "             from_checkpoint=False,\n",
    "             path_to_checkpoint=None,\n",
    "             wp_n_epochs=1,\n",
    "             epoch=0,\n",
    "             num_samples=10000,\n",
    "             warmup_exp_beta=0.8,\n",
    "             embedding_dim=128,\n",
    "             graph_size=20\n",
    "             ): ...\n",
    "```\n",
    "\n",
    "| Parameter           | Description |\n",
    "| :---:               | :--- |\n",
    "| model               | Initial ML model to use as baseline |\n",
    "| filename            | Suffix for checkpoint name for the model (Keras). Model name template is `{path_to_checkpoint}/baseline_checkpoint_epoch_{epoch}_{filename}.h5`|\n",
    "| from_checkpoint     | Flag to use a saved checkpoint following the suffix provided. |\n",
    "| path_to_checkpoint  | Directory where to save baseline |\n",
    "| wp_n_epochs         | Number of warm up epochs |\n",
    "| epoch               | Starting epoch number |\n",
    "| num_samples         | Size of dataset generated for baseline. Used when deciding whether current model is statistically better than the baseline. |\n",
    "| warmup_exp_beta     | weight used during warm up. Balances incorporation of Exponential Moving Average and Rollout Baselines |\n",
    "| embedding_dim       | used for loading up model. |\n",
    "| graph_size          | Used for loading up model. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb9455ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating baseline model on baseline dataset (epoch = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:11<00:00,  1.10s/it]\n"
     ]
    }
   ],
   "source": [
    "from reinforce_baseline import RolloutBaseline\n",
    "from time import strftime, gmtime\n",
    "\n",
    "model              = model_amd\n",
    "graph_size         = 20\n",
    "filename           = 'VRP_{}_{}'.format(graph_size, strftime(\"%Y-%m-%d\", gmtime()))\n",
    "from_checkpoint    = False\n",
    "path_to_checkpoint = None\n",
    "wp_n_epochs        = 5\n",
    "epoch              = 0\n",
    "num_samples        = 10_000\n",
    "warmup_exp_beta    = 0.8\n",
    "embedding_dim      = embedding_dim\n",
    "\n",
    "\n",
    "baseline = RolloutBaseline(model             = model,\n",
    "                           filename          = filename,\n",
    "                           from_checkpoint   = from_checkpoint,\n",
    "                           path_to_checkpoint= path_to_checkpoint,\n",
    "                           wp_n_epochs       = wp_n_epochs,\n",
    "                           epoch             = epoch,\n",
    "                           num_samples       = num_samples,\n",
    "                           embedding_dim     = embedding_dim,\n",
    "                           graph_size        = graph_size\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ae1d45",
   "metadata": {},
   "source": [
    "### Creating Problem Dataset\n",
    "\n",
    "Dataset generation is provided by the `utils.py` module. The recommended function to generate data is `create_data_on_disk`:\n",
    "\n",
    "```python\n",
    "def create_data_on_disk(\n",
    "    graph_size, \n",
    "    num_samples, \n",
    "    is_save=True, \n",
    "    filename=None, \n",
    "    is_return=False, \n",
    "    seed=1234): ...\n",
    "\n",
    "```\n",
    "\n",
    "| Parameter | Description|\n",
    "| :---:     | :---       |\n",
    "| graph_size  | Number of nodes to generate |\n",
    "| num_samples | Size of dataset |\n",
    "| is_save     | Flag for saving to disk |\n",
    "| filename    | Suffix of dataset: 'Validation\\_dataset\\_{filename}.pkl' |\n",
    "| is_return   | Whether to return dataset or not |\n",
    "| seed        | Seed for generation |\n",
    "\n",
    "Note that the data generated will use the TensorFlow API for datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15219254",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_data_on_disk\n",
    "\n",
    "graph_size  = graph_size\n",
    "num_samples = 10_000\n",
    "is_save     = True\n",
    "filename    = filename\n",
    "is_return   = True\n",
    "seed        = 42\n",
    "\n",
    "validation_dataset = create_data_on_disk(graph_size =graph_size,\n",
    "                                         num_samples=num_samples,\n",
    "                                         is_save    =is_save,\n",
    "                                         filename   =filename,\n",
    "                                         is_return  =is_return,\n",
    "                                         seed       =seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957e5e95",
   "metadata": {},
   "source": [
    "#### Vizualization of output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2527f478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17432/106837068.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  graph = graph.assign(type='node').append(goal, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.090576</td>\n",
       "      <td>0.105941</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.672503</td>\n",
       "      <td>0.656092</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.402797</td>\n",
       "      <td>0.798440</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.893440</td>\n",
       "      <td>0.426028</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260078</td>\n",
       "      <td>0.359273</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.652982</td>\n",
       "      <td>0.425485</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.080519</td>\n",
       "      <td>0.855694</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.147657</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.521012</td>\n",
       "      <td>0.173180</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.042330</td>\n",
       "      <td>0.255430</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.056516</td>\n",
       "      <td>0.140128</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.484007</td>\n",
       "      <td>0.264015</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.139997</td>\n",
       "      <td>0.855501</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.504407</td>\n",
       "      <td>0.060363</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.184143</td>\n",
       "      <td>0.334701</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.951709</td>\n",
       "      <td>0.101621</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.515714</td>\n",
       "      <td>0.946507</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.889182</td>\n",
       "      <td>0.069698</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.350460</td>\n",
       "      <td>0.026653</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.699666</td>\n",
       "      <td>0.429203</td>\n",
       "      <td>node</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.952271</td>\n",
       "      <td>0.677408</td>\n",
       "      <td>depot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x         y   type\n",
       "0   0.090576  0.105941   node\n",
       "1   0.672503  0.656092   node\n",
       "2   0.402797  0.798440   node\n",
       "3   0.893440  0.426028   node\n",
       "4   0.260078  0.359273   node\n",
       "5   0.652982  0.425485   node\n",
       "6   0.080519  0.855694   node\n",
       "7   0.147657  0.004048   node\n",
       "8   0.521012  0.173180   node\n",
       "9   0.042330  0.255430   node\n",
       "10  0.056516  0.140128   node\n",
       "11  0.484007  0.264015   node\n",
       "12  0.139997  0.855501   node\n",
       "13  0.504407  0.060363   node\n",
       "14  0.184143  0.334701   node\n",
       "15  0.951709  0.101621   node\n",
       "16  0.515714  0.946507   node\n",
       "17  0.889182  0.069698   node\n",
       "18  0.350460  0.026653   node\n",
       "19  0.699666  0.429203   node\n",
       "20  0.952271  0.677408  depot"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "gen_data = next(validation_dataset.batch(6_000).as_numpy_iterator())\n",
    "sample   = 0\n",
    "__type   = 1 # 0: space nodes, 1: depot node\n",
    "graph    = pd.DataFrame(gen_data[__type][sample], columns=['x', 'y'])\n",
    "\n",
    "goal = {\n",
    "    'x': gen_data[0][sample][0], \n",
    "    'y': gen_data[0][sample][1], \n",
    "    'type': 'depot'\n",
    "}\n",
    "\n",
    "graph = graph.assign(type='node').append(goal, ignore_index=True)\n",
    "\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89154ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='x', ylabel='y'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(data=graph, x='x', y='y', hue='type', style='type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc391a9",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "The developers provide a training function for orchestrating the training and rollout process of training.\n",
    "\n",
    "```python\n",
    "def train_model(optimizer,\n",
    "                model_tf,\n",
    "                baseline,\n",
    "                validation_dataset,\n",
    "                samples = 1280000,\n",
    "                batch = 128,\n",
    "                val_batch_size = 1000,\n",
    "                start_epoch = 0,\n",
    "                end_epoch = 5,\n",
    "                from_checkpoint = False,\n",
    "                grad_norm_clipping = 1.0,\n",
    "                batch_verbose = 1000,\n",
    "                graph_size = 20,\n",
    "                filename = None\n",
    "                ): ...\n",
    "```\n",
    "\n",
    "| Parameter          | Description |\n",
    "| :----------------: | :---------- |\n",
    "| optimizer          | Optimizer to be used for training |\n",
    "| model_tf           | Training model to use             |\n",
    "| baseline           | Initial baseline                  |\n",
    "| validation_dataset | Generated dataset for validation (used at the end) |\n",
    "| samples            | Number of samples to use for each learning epoch |\n",
    "| batch              | Size of batches for learning      |\n",
    "| val_batch_size     | Number of batches to use for validation (averaged out at the end for final score)|\n",
    "| start_epoch        | Initial epoch configuration       |\n",
    "| end_epoch          | Last epoch                        |\n",
    "| from_checkpoint    | Flag for loading checkpoint       |\n",
    "| grad_norm_clipping | Clipping/rescaling of gradients   |\n",
    "| batch_verbose      | Verbosity of output               |\n",
    "| graph_size         | Number of nodes for graph generated |\n",
    "| filename           | Suffix of saved model: `VRP_{graph_size}_{date}` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e8fbe54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: greedy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 0: 1it [00:02,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 293.2804870605469, clipped_norm = 0.9999998807907104\n",
      "Epoch 0 (batch = 0): Loss: -63.02037048339844: Cost: 12.00259017944336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 0: 16it [00:17,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 candidate mean 9.853118896484375, baseline epoch 0 mean 20.722900390625, difference -10.869781494140625\n",
      "p-value: 0.0\n",
      "Update baseline\n",
      "Evaluating baseline model on baseline dataset (epoch = 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha was updated to 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.858499526977539\n",
      "2022-10-17 11:52:09 Epoch 0: Loss: 14.100600242614746: Cost: 9.962306022644043\n",
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 1: 1it [00:01,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 5.367676734924316, clipped_norm = 1.0\n",
      "Epoch 1 (batch = 0): Loss: -23.488666534423828: Cost: 11.016277313232422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 1: 16it [00:24,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 candidate mean 9.806806564331055, baseline epoch 1 mean 9.860352516174316, difference -0.05354595184326172\n",
      "p-value: 1.6929304016449183e-07\n",
      "Update baseline\n",
      "Evaluating baseline model on baseline dataset (epoch = 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha was updated to 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.81879997253418\n",
      "2022-10-17 11:52:59 Epoch 1: Loss: -6.375464916229248: Cost: 10.589012145996094\n",
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 2: 1it [00:01,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 7.267955303192139, clipped_norm = 1.0\n",
      "Epoch 2 (batch = 0): Loss: -1.5187013149261475: Cost: 10.420454025268555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 2: 16it [00:24,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 candidate mean 9.829795837402344, baseline epoch 2 mean 9.834162712097168, difference -0.004366874694824219\n",
      "p-value: 0.2974158083518947\n",
      "alpha was updated to 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.82229995727539\n",
      "2022-10-17 11:53:36 Epoch 2: Loss: -1.1043213605880737: Cost: 10.087339401245117\n",
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 3: 1it [00:01,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 6.990487098693848, clipped_norm = 1.0\n",
      "Epoch 3 (batch = 0): Loss: -0.515728235244751: Cost: 9.700668334960938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 3: 16it [00:25,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 candidate mean 9.821253776550293, baseline epoch 3 mean 9.834162712097168, difference -0.012908935546875\n",
      "p-value: 0.09961207724649358\n",
      "alpha was updated to 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.810099601745605\n",
      "2022-10-17 11:54:15 Epoch 3: Loss: -2.3056914806365967: Cost: 9.944756507873535\n",
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 4: 1it [00:01,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 5.599606037139893, clipped_norm = 1.0\n",
      "Epoch 4 (batch = 0): Loss: -2.150501251220703: Cost: 9.988107681274414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 4: 16it [00:23,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 candidate mean 9.820069313049316, baseline epoch 4 mean 9.834162712097168, difference -0.014093399047851562\n",
      "p-value: 0.07539925386697402\n",
      "alpha was updated to 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.823399543762207\n",
      "2022-10-17 11:54:51 Epoch 4: Loss: -2.3622500896453857: Cost: 10.026713371276855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 5: 1it [00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 10.66225814819336, clipped_norm = 1.0\n",
      "Epoch 5 (batch = 0): Loss: -1.4365882873535156: Cost: 9.75882339477539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 5: 16it [00:15,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 candidate mean 9.81631088256836, baseline epoch 5 mean 9.834162712097168, difference -0.017851829528808594\n",
      "p-value: 0.010507561507004397\n",
      "Update baseline\n",
      "Evaluating baseline model on baseline dataset (epoch = 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.68it/s]\n",
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.816399574279785\n",
      "2022-10-17 11:55:32 Epoch 5: Loss: -2.4232044219970703: Cost: 10.014386177062988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 6: 1it [00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 8.616179466247559, clipped_norm = 1.0\n",
      "Epoch 6 (batch = 0): Loss: -0.4929308295249939: Cost: 10.204660415649414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 6: 16it [00:15,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 candidate mean 9.803393363952637, baseline epoch 6 mean 9.808073997497559, difference -0.004680633544921875\n",
      "p-value: 0.2917310783360362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.815299987792969\n",
      "2022-10-17 11:56:01 Epoch 6: Loss: -3.116130828857422: Cost: 10.064619064331055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 7: 1it [00:01,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 25.470882415771484, clipped_norm = 1.0000001192092896\n",
      "Epoch 7 (batch = 0): Loss: -14.628704071044922: Cost: 10.187479972839355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 7: 16it [00:17,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 candidate mean 9.862622261047363, baseline epoch 7 mean 9.808073997497559, difference 0.05454826354980469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.858200073242188\n",
      "2022-10-17 11:56:31 Epoch 7: Loss: -12.232707977294922: Cost: 10.199662208557129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 8: 1it [00:01,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 13.045051574707031, clipped_norm = 1.0000001192092896\n",
      "Epoch 8 (batch = 0): Loss: -5.783011436462402: Cost: 10.006368637084961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 8: 16it [00:16,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 candidate mean 9.841341972351074, baseline epoch 8 mean 9.808073997497559, difference 0.033267974853515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.844799995422363\n",
      "2022-10-17 11:57:00 Epoch 8: Loss: -3.2671022415161133: Cost: 9.998845100402832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 9: 1it [00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 8.452441215515137, clipped_norm = 1.0\n",
      "Epoch 9 (batch = 0): Loss: 3.1973681449890137: Cost: 9.848896980285645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 9: 16it [00:15,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 candidate mean 9.826662063598633, baseline epoch 9 mean 9.808073997497559, difference 0.01858806610107422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.82919979095459\n",
      "2022-10-17 11:57:28 Epoch 9: Loss: -1.1997342109680176: Cost: 10.0982084274292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 10: 1it [00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 19.371122360229492, clipped_norm = 1.0\n",
      "Epoch 10 (batch = 0): Loss: 3.0224204063415527: Cost: 9.60272216796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 10: 16it [00:15,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 candidate mean 9.822569847106934, baseline epoch 10 mean 9.808073997497559, difference 0.014495849609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.832500457763672\n",
      "2022-10-17 11:57:56 Epoch 10: Loss: -1.9165420532226562: Cost: 9.855827331542969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 11: 1it [00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 17.14249038696289, clipped_norm = 1.0\n",
      "Epoch 11 (batch = 0): Loss: -1.7857904434204102: Cost: 9.956026077270508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 11: 16it [00:15,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 11)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 candidate mean 9.833796501159668, baseline epoch 11 mean 9.808073997497559, difference 0.025722503662109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.828399658203125\n",
      "2022-10-17 11:58:25 Epoch 11: Loss: -1.722939133644104: Cost: 9.870121002197266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 12: 1it [00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 19.391212463378906, clipped_norm = 1.0\n",
      "Epoch 12 (batch = 0): Loss: -7.51214599609375: Cost: 10.039468765258789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 12: 16it [00:15,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 candidate mean 9.861653327941895, baseline epoch 12 mean 9.808073997497559, difference 0.05357933044433594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.838399887084961\n",
      "2022-10-17 11:58:53 Epoch 12: Loss: -2.1235172748565674: Cost: 9.955738067626953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 13: 1it [00:00,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 11.007966041564941, clipped_norm = 1.0\n",
      "Epoch 13 (batch = 0): Loss: -4.037008285522461: Cost: 9.904657363891602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 13: 16it [00:16,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 candidate mean 9.840658187866211, baseline epoch 13 mean 9.808073997497559, difference 0.032584190368652344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.834099769592285\n",
      "2022-10-17 11:59:22 Epoch 13: Loss: -2.835555076599121: Cost: 10.01561164855957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 14: 1it [00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 21.00539779663086, clipped_norm = 1.0\n",
      "Epoch 14 (batch = 0): Loss: -1.1570839881896973: Cost: 9.693327903747559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 14: 16it [00:16,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 candidate mean 9.820295333862305, baseline epoch 14 mean 9.808073997497559, difference 0.012221336364746094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.827400207519531\n",
      "2022-10-17 11:59:51 Epoch 14: Loss: -2.0816256999969482: Cost: 9.926193237304688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 15: 1it [00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 13.81588363647461, clipped_norm = 1.0\n",
      "Epoch 15 (batch = 0): Loss: -2.989360809326172: Cost: 9.863649368286133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 15: 16it [00:15,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 candidate mean 9.819964408874512, baseline epoch 15 mean 9.808073997497559, difference 0.011890411376953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.817399978637695\n",
      "2022-10-17 12:00:20 Epoch 15: Loss: -2.238001585006714: Cost: 9.932905197143555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 16: 1it [00:01,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 7.760614395141602, clipped_norm = 1.0\n",
      "Epoch 16 (batch = 0): Loss: 0.18336451053619385: Cost: 10.062042236328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 16: 16it [00:16,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 candidate mean 9.80826187133789, baseline epoch 16 mean 9.808073997497559, difference 0.00018787384033203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.821499824523926\n",
      "2022-10-17 12:00:49 Epoch 16: Loss: -2.186630964279175: Cost: 9.957578659057617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 17: 1it [00:01,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 10.611992835998535, clipped_norm = 0.9999999403953552\n",
      "Epoch 17 (batch = 0): Loss: -7.1740593910217285: Cost: 9.829141616821289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 17: 16it [00:15,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 candidate mean 9.803353309631348, baseline epoch 17 mean 9.808073997497559, difference -0.0047206878662109375\n",
      "p-value: 0.36477145746360384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.818499565124512\n",
      "2022-10-17 12:01:18 Epoch 17: Loss: -2.942793846130371: Cost: 9.93968391418457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 18: 1it [00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 12.708499908447266, clipped_norm = 1.0\n",
      "Epoch 18 (batch = 0): Loss: 0.9658908843994141: Cost: 9.746603965759277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 18: 16it [00:15,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 candidate mean 9.801177024841309, baseline epoch 18 mean 9.808073997497559, difference -0.00689697265625\n",
      "p-value: 0.30458117216213404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.80720043182373\n",
      "2022-10-17 12:01:46 Epoch 18: Loss: -4.294456481933594: Cost: 10.017264366149902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 19: 1it [00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 13.266112327575684, clipped_norm = 1.0\n",
      "Epoch 19 (batch = 0): Loss: -6.386463642120361: Cost: 10.114887237548828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 19: 16it [00:15,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 candidate mean 9.820680618286133, baseline epoch 19 mean 9.808073997497559, difference 0.012606620788574219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.809100151062012\n",
      "2022-10-17 12:02:15 Epoch 19: Loss: -9.199366569519043: Cost: 10.28327465057373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 20: 1it [00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 23.556156158447266, clipped_norm = 1.0\n",
      "Epoch 20 (batch = 0): Loss: -9.120654106140137: Cost: 10.331871032714844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 20: 16it [00:16,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 candidate mean 9.805380821228027, baseline epoch 20 mean 9.808073997497559, difference -0.00269317626953125\n",
      "p-value: 0.4202496645713425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.80210018157959\n",
      "2022-10-17 12:02:45 Epoch 20: Loss: -1.7121723890304565: Cost: 9.87697696685791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 21: 1it [00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 9.480424880981445, clipped_norm = 1.0\n",
      "Epoch 21 (batch = 0): Loss: 0.10679271817207336: Cost: 9.749665260314941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 21: 16it [00:17,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 candidate mean 9.798458099365234, baseline epoch 21 mean 9.808073997497559, difference -0.009615898132324219\n",
      "p-value: 0.23789349066825477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.806099891662598\n",
      "2022-10-17 12:03:15 Epoch 21: Loss: -12.115229606628418: Cost: 10.225159645080566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 22: 1it [00:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 20.84623146057129, clipped_norm = 1.0\n",
      "Epoch 22 (batch = 0): Loss: -30.79697036743164: Cost: 10.99146556854248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 22: 16it [00:16,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 candidate mean 9.797015190124512, baseline epoch 22 mean 9.808073997497559, difference -0.011058807373046875\n",
      "p-value: 0.2070391736690857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 9.801300048828125\n",
      "2022-10-17 12:03:44 Epoch 22: Loss: -8.441415786743164: Cost: 10.103693008422852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current decode type: sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 23: 1it [00:01,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_global_norm = 13.457284927368164, clipped_norm = 0.9999999403953552\n",
      "Epoch 23 (batch = 0): Loss: -1.0631903409957886: Cost: 9.634129524230957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch calculation at epoch 23: 16it [00:17,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating candidate model on baseline dataset (callback epoch = 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:06<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 candidate mean 9.786911010742188, baseline epoch 23 mean 9.808073997497559, difference -0.021162986755371094\n",
      "p-value: 0.059885070475588845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rollout greedy execution:  60%|████████████████████████████████████████████████████████████████████████████████████                                                        | 6/10 [00:04<00:02,  1.42it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m graph_size         \u001b[38;5;241m=\u001b[39m graph_size\n\u001b[1;32m     17\u001b[0m filename           \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m---> 19\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_tf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mval_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43mend_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mend_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfrom_checkpoint\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfrom_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgrad_norm_clipping\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgrad_norm_clipping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_verbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgraph_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgraph_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/coding/github/DynamicAttentionModel-VRP/train.py:111\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(optimizer, model_tf, baseline, validation_dataset, samples, batch, val_batch_size, start_epoch, end_epoch, from_checkpoint, grad_norm_clipping, batch_verbose, graph_size, filename)\u001b[0m\n\u001b[1;32m    108\u001b[0m model_tf\u001b[38;5;241m.\u001b[39msave_weights(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_checkpoint_epoch_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, filename), save_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Validate current model\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m val_cost \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_batch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m val_cost_avg\u001b[38;5;241m.\u001b[39mappend(val_cost)\n\u001b[1;32m    114\u001b[0m train_loss_results\u001b[38;5;241m.\u001b[39mappend(epoch_loss_avg\u001b[38;5;241m.\u001b[39mresult())\n",
      "File \u001b[0;32m~/coding/github/DynamicAttentionModel-VRP/reinforce_baseline.py:50\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(dataset, model, batch_size)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate\u001b[39m(dataset, model, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124;03m\"\"\"Validates model on given dataset in greedy mode\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     val_costs \u001b[38;5;241m=\u001b[39m \u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     set_decode_type(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msampling\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m     mean_cost \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(val_costs)\n",
      "File \u001b[0;32m~/coding/github/DynamicAttentionModel-VRP/reinforce_baseline.py:41\u001b[0m, in \u001b[0;36mrollout\u001b[0;34m(model, dataset, batch_size, disable_tqdm)\u001b[0m\n\u001b[1;32m     38\u001b[0m costs_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataset\u001b[38;5;241m.\u001b[39mbatch(batch_size), disable\u001b[38;5;241m=\u001b[39mdisable_tqdm, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRollout greedy execution\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 41\u001b[0m     cost, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     costs_list\u001b[38;5;241m.\u001b[39mappend(cost)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mconcat(costs_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/keras/engine/training.py:557\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[1;32m    555\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[0;32m--> 557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/keras/engine/base_layer.py:1097\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[1;32m   1096\u001b[0m ):\n\u001b[0;32m-> 1097\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/keras/utils/traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[0;32m~/coding/github/DynamicAttentionModel-VRP/attention_dynamic_model.py:254\u001b[0m, in \u001b[0;36mAttentionDynamicModel.call\u001b[0;34m(self, inputs, return_pi)\u001b[0m\n\u001b[1;32m    251\u001b[0m Q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_heads(Q, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)  \u001b[38;5;66;03m# (batch_size, num_heads, 1, head_depth)\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# get current mask\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, 1, n_nodes) with True/False indicating where agent can go\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# compute MHA decoder vectors for current mask\u001b[39;00m\n\u001b[1;32m    257\u001b[0m mha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_mha(Q, K, V, mask)  \u001b[38;5;66;03m# (batch_size, 1, output_dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/coding/github/DynamicAttentionModel-VRP/enviroment.py:92\u001b[0m, in \u001b[0;36mAgentVRP.get_mask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# We can choose depot if 1) we are not in depot OR 2) all nodes are visited\u001b[39;00m\n\u001b[1;32m     90\u001b[0m mask_depot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_depot \u001b[38;5;241m&\u001b[39m (tf\u001b[38;5;241m.\u001b[39mreduce_sum(tf\u001b[38;5;241m.\u001b[39mcast(mask_loc \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, tf\u001b[38;5;241m.\u001b[39mint32), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mmask_depot\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m, mask_loc], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:1071\u001b[0m, in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\n\u001b[1;32m   1067\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1068\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrided_slice\u001b[39m\u001b[38;5;124m\"\u001b[39m, [tensor] \u001b[38;5;241m+\u001b[39m begin \u001b[38;5;241m+\u001b[39m end \u001b[38;5;241m+\u001b[39m strides,\n\u001b[1;32m   1069\u001b[0m     skip_on_eager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m name:\n\u001b[1;32m   1070\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m begin:\n\u001b[0;32m-> 1071\u001b[0m     packed_begin, packed_end, packed_strides \u001b[38;5;241m=\u001b[39m (\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m)\u001b[49m, stack(end),\n\u001b[1;32m   1072\u001b[0m                                                 stack(strides))\n\u001b[1;32m   1073\u001b[0m     \u001b[38;5;66;03m# TODO(mdan): Instead of implicitly casting, it's better to enforce the\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m     \u001b[38;5;66;03m# same dtypes.\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (packed_begin\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mint64 \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m         packed_end\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mint64 \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m         packed_strides\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mint64):\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:1468\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1466\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1467\u001b[0m     \u001b[38;5;66;03m# If the input is a constant list, it can be converted to a constant op\u001b[39;00m\n\u001b[0;32m-> 1468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1469\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m):\n\u001b[1;32m   1470\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Input list contains non-constant tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1638\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1629\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1630\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1631\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1634\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1635\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m   1637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1638\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1641\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:343\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    341\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    342\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 343\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[1;32m    282\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    303\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from train import train_model\n",
    "\n",
    "\n",
    "optimizer          = optimizer\n",
    "model_tf           = model\n",
    "baseline           = baseline\n",
    "validation_dataset = validation_dataset\n",
    "samples            = 512\n",
    "batch              = 32\n",
    "val_batch_size     = 1_000\n",
    "start_epoch        = 0\n",
    "end_epoch          = 30\n",
    "from_checkpoint    = False\n",
    "grad_norm_clipping = 1.0\n",
    "batch_verbose      = 1_000\n",
    "graph_size         = graph_size\n",
    "filename           = filename\n",
    "\n",
    "train_model(optimizer =optimizer,\n",
    "            model_tf = model_tf,\n",
    "            baseline = baseline,\n",
    "            validation_dataset = validation_dataset,\n",
    "            samples = samples,\n",
    "            batch = batch,\n",
    "            val_batch_size = val_batch_size,\n",
    "            start_epoch = start_epoch,\n",
    "            end_epoch = end_epoch,\n",
    "            from_checkpoint = from_checkpoint,\n",
    "            grad_norm_clipping = grad_norm_clipping,\n",
    "            batch_verbose = batch_verbose,\n",
    "            graph_size = graph_size,\n",
    "            filename = filename\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70be4eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf.save_weights(\"checkpoints/AM-D_oct_17_20_nodes.ckp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ede76a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
